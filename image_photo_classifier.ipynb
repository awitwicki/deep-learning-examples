{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Check runtime for nvidia graphics card\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aqd9pbynnbv"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "uvFUEcA2nqG6"
   },
   "outputs": [],
   "source": [
    "#@title NN parameters\n",
    "IMG_SIZE = 224 #@param {type:\"integer\"}\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "SPLIT_WEIGHTS = (8, 1, 1)\n",
    "BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "uEeq9_8pnuix"
   },
   "outputs": [],
   "source": [
    "#@title (For google colab) Download and unpack dataset\n",
    "\n",
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive_path = '/content/drive/MyDrive' #@param {type:\"string\"}\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Download and unpack dataset\n",
    "!mkdir dataset\n",
    "!unzip drive/MyDrive/image_photo_classifier/dataset/photos.zip -d dataset\n",
    "!unzip drive/MyDrive/image_photo_classifier/dataset/images.zip -d dataset\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21antv48nqJz",
    "outputId": "07261773-caec-4919-91e3-14f7b30f6f36"
   },
   "outputs": [],
   "source": [
    "#@title Load images data\n",
    "    \n",
    "def get_files_in_folder(path: str) -> list:\n",
    "    return list(glob.glob(f'{path}/*.jpg'))\n",
    "\n",
    "def read_image(image_path) -> list:\n",
    "    target_size = (IMG_SIZE, IMG_SIZE)\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, color_mode = \"rgb\", target_size=target_size)\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    return x\n",
    "\n",
    "# Create dataset\n",
    "x_photos = [read_image(x) for x in get_files_in_folder('dataset/photos')]\n",
    "x_images = [read_image(x) for x in get_files_in_folder('dataset/images')[:2000]]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "[(x_train.append(f), y_train.append(0)) for f in x_photos] # photo as photo\n",
    "[(x_train.append(f), y_train.append(1)) for f in x_images] # images as image\n",
    "\n",
    "x_train = np.array(x_train).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "\n",
    "print('Done')\n",
    "print(f'Image shapes: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "rOQ7wgCKnqMi"
   },
   "outputs": [],
   "source": [
    "#@title Create TensorFlow compatible dataset and free memory\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_train, y_train, test_size=0.20)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x, test_y, test_size=0.50)\n",
    "\n",
    "train_y = train_y.astype(np.float32)\n",
    "test_y = test_y.astype(np.float32)\n",
    "\n",
    "#free memory\n",
    "del x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-vNuT53unqO2",
    "outputId": "e9ab7a95-d84e-461a-ff94-8a482ce525cc"
   },
   "outputs": [],
   "source": [
    "#@title Show random image from dataset\n",
    "\n",
    "index = np.random.choice(len(test_x))\n",
    "img = test_x[index]\n",
    "img = img.reshape(IMG_SHAPE)\n",
    "\n",
    "plt.imshow((img.reshape(IMG_SHAPE)).astype(np.uint8), vmin=0, vmax=255)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3kgl89knqRC",
    "outputId": "c001e34a-754a-41f7-a632-051cc8145d06"
   },
   "outputs": [],
   "source": [
    "#@title MobileNetV2 model\n",
    "\n",
    "base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SHAPE,\n",
    "    pooling=None)\n",
    "    \n",
    "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate= 0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "am3YXYIanqTP",
    "outputId": "4aa63627-6872-46d2-e5c4-ff2ebbf2ece3"
   },
   "outputs": [],
   "source": [
    "#@title Train model\n",
    "epochs = 25 #@param {type:\"slider\", min:1, max:55, step:1}\n",
    "%time score = model.fit(train_x, train_y, batch_size=64, epochs=epochs, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "n92mgtD-nqXT",
    "outputId": "12434064-3043-468d-dad7-ef3a645b3591"
   },
   "outputs": [],
   "source": [
    "#@title Train history\n",
    "\n",
    "acc = score.history['accuracy']\n",
    "val_acc = score.history['val_accuracy']\n",
    "\n",
    "loss = score.history['loss']\n",
    "val_loss = score.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "IEFKbJNRv7CH",
    "outputId": "7048167b-9ba3-4f08-a01d-58c928aaf76c"
   },
   "outputs": [],
   "source": [
    "#@title Confusion matrix\n",
    "import seaborn as sns\n",
    "\n",
    "label_names = ['screen', 'photo']\n",
    "\n",
    "def predict_class_label_number(dataset):\n",
    "  results = []\n",
    "\n",
    "  for img in dataset:\n",
    "      img = img.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "      result = model.predict(img, verbose=0)\n",
    "      res = min(max(result[0][0], 0), 1)\n",
    "      results.append(res)\n",
    "\n",
    "  return results\n",
    "\n",
    "def show_confusion_matrix(cm, labels):\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(cm, xticklabels=labels, yticklabels=labels, annot=True, fmt='g')\n",
    "  plt.xlabel('Prediction')\n",
    "  plt.ylabel('Label')\n",
    "  plt.show()\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(val_y, predict_class_label_number(val_x), num_classes=len(label_names))\n",
    "\n",
    "show_confusion_matrix(confusion_mtx, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "85eSl3YJnqaC",
    "outputId": "8a28946b-c493-4555-a397-cfcf621471f5"
   },
   "outputs": [],
   "source": [
    "#@title Make 9 predictions\n",
    "indexes = np.random.choice(len(test_x), 29)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    img = test_x[indexes[i]]\n",
    "    img = img.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    result = model.predict(img, verbose=0)\n",
    "    class_label = \"image\" if result[0][0] > 0 else \"photo\"\n",
    "    str_result = f\"{class_label}\"\n",
    "    plt.title(str_result)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((img.reshape(IMG_SIZE, IMG_SIZE, 3)).astype(np.uint8))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naVHNJ3NmM_-",
    "outputId": "7e91e66f-1528-49f0-93ac-afe81a3a7f37"
   },
   "outputs": [],
   "source": [
    "#@title Convert model\n",
    "\n",
    "model_name = 'resnet50v2_image_photo_predictor_rgb_v1.0_224' #@param {type:\"string\"}\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Comment this line if you run this notebook in google colab!\n",
    "drive_path = 'image_photo_classifier/model'\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "save_model = True #@param {type:\"boolean\"}\n",
    "if save_model:\n",
    "    print(f'Saving model to {drive_path}/{model_name}.h5')\n",
    "    model.save(f'{drive_path}/{model_name}.h5')\n",
    "    print(f'Saved')\n",
    "\n",
    "\n",
    "save_tfjs_model = True  #@param {type:\"boolean\"}\n",
    "if save_tfjs_model:\n",
    "    !pip install tensorflowjs\n",
    "    import tensorflowjs as tfjs\n",
    "    clear_output()\n",
    "    tfjs.converters.save_keras_model(model, f\"{drive_path}/{model_name}\")\n",
    "\n",
    "\n",
    "save_tflite_model = True #@param {type:\"boolean\"}\n",
    "if save_tflite_model:\n",
    "    print(f'Saving model to {drive_path}/{model_name}.tflite')\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(f'{drive_path}/{model_name}.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        print(f'Saved')\n",
    "\n",
    "\n",
    "save_tflite_quant_model = True #@param {type:\"boolean\"}\n",
    "if save_tflite_quant_model:\n",
    "    print(f'Saving quant model to {drive_path}/{model_name}_quant.tflite')\n",
    "    # A generator that provides a representative dataset\n",
    "    def representative_data_gen():\n",
    "        for image in test_x[:100]:\n",
    "          im = image.reshape(1, IMG_SHAPE[0], IMG_SHAPE[0], IMG_SHAPE[2]).astype(np.float32)\n",
    "          yield [im]\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    # This enables quantization\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # This sets the representative dataset for quantization\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    # This ensures that if any ops can't be quantized, the converter throws an error\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "    converter.target_spec.supported_types = [tf.int8]\n",
    "    # These set the input and output tensors to uint8 (added in r2.3)\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "    with open(f'{drive_path}/{model_name}_quant.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        print(f'Saved')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "monitor_photo_clessifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
